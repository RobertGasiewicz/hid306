{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is a technique to analyze all the variables those influence target variable for better predictions. Part of feature engineering, we will need to create new featues to make the data to be more expressive.\n",
    "Analysing categorical variables with an intent to convert them into numerical factors as most of the machine learning algorithms expect all the variables to be numerical to be effective. Some of the categorical variables are ordinal. we can use T-shirt sizes: small, medium and large as an example to explain an ordinal variable. When we convert this category varible into numeric encoding, we need to retain the fact that there is an implicit order within the values. Supposing we give ordinal encoding as - small = 1, medium = 2 and large = 3; we will satisfy the implict order or weightage and that helps in modeling the system by elevating the importance of this implict ordering in the values of the ordinal variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few other encoding techniques, such as one-hot, binary, polynomial and helmert. We will use ordinal and one-hot encoding techniques for this data set. One-hot encoding converts the category variable into many binary vectors, one new numeric variable for each value in the category. Assume that we have a category variable called signal-light with three possible values: green, yellow and red. We will need to convert these values into numeric - green = 1, yellow = 2 and red = 3. When we apply one-hot encoding on this variable, basically we are creating three new categorical variables - signal-light-green, signal-light-yellow and signal-light-red along with the original variable - signal-light, each is pretty much a binary vector having 1s for all the corresponding values; otherwise 0s. With hot-encoding, we are basically increasing the dimensions in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "   \n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mcheruvu/notebook\n",
      "\n",
      "The train data has 1460 rows and 81 columns\n",
      "The test data has 1459 rows and 80 columns\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "print(\"\")\n",
    "\n",
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "\n",
    "print ('The train data has {0} rows and {1} columns'.format(train.shape[0],train.shape[1]))    \n",
    "print ('The test data has {0} rows and {1} columns'.format(test.shape[0],test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorize Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze all categorical variables and apply proper techniques, such as manual factorization and hot/dummy encoding to factorize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(df, col_name, fill_val):\n",
    "    if fill_val is not None:\n",
    "        df[col_name].fillna(fill_val, inplace=True)\n",
    "\n",
    "    dummies = pd.get_dummies(df[col_name], prefix=\"_\" + col_name)\n",
    "    df = df.join(dummies)\n",
    "    df = df.drop([col_name], axis=1)\n",
    "    return df\n",
    "#end def\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def factorize(df, column, fill_na=None):\n",
    "    le = LabelEncoder()\n",
    "    if fill_na is not None:\n",
    "        df[column].fillna(fill_na, inplace=True)\n",
    "    le.fit(df[column].unique())\n",
    "    df[column] = le.transform(df[column])\n",
    "    return df\n",
    "#end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \n",
    "    df['MSSubCls'] = df['MSSubClass']\n",
    "    df = get_one_hot(df,'MSSubCls',None)\n",
    "    df = factorize(df,'MSSubClass',None)\n",
    "\n",
    "    # df = get_one_hot(df, 'MSZoning',None)\n",
    "\n",
    "    neighborhood = df['Neighborhood']\n",
    "    zone = df['MSZoning']\n",
    "\n",
    "    corr = pd.crosstab(neighborhood,zone)\n",
    "    print(corr)\n",
    "    # zone = df.iloc[[1]].apply(lambda row: print(corr.loc[row['Neighborhood']].idxmax(axis=1)) ,axis=1)\n",
    "    # print(df.iloc[[1]])\n",
    "    zone = df.apply(lambda row: (corr.loc[row['Neighborhood']]).idxmax(axis=1) if pd.isnull(row['MSZoning']) else row['MSZoning'],axis=1)\n",
    "    df = df.drop(['MSZoning'],axis=1)\n",
    "    df['MSZoning'] = zone\n",
    "    df = get_one_hot(df,'MSZoning',None)\n",
    "\n",
    "    lot_frontage_by_neighborhood = df[\"LotFrontage\"].groupby(df[\"Neighborhood\"])\n",
    "    for key, group in lot_frontage_by_neighborhood:\n",
    "        idx = (df[\"Neighborhood\"] == key) & (df[\"LotFrontage\"].isnull())\n",
    "        df.loc[idx, \"LotFrontage\"] = group.median() \n",
    "    \n",
    "    df['Street'].fillna('Grvl', inplace=True)\n",
    "    street_dict = {'Grvl':0,'Pave':1}\n",
    "    df['Street'].replace(street_dict, inplace=True)\n",
    "\n",
    "    # df['LotArea'] = df['LotArea'].map(lambda x:np.log1p(x))\n",
    " \n",
    "    # print(df['Alley'].mode())\n",
    "\n",
    "    df['Alley'].fillna('NA', inplace=True)  \n",
    "    print(df.Alley.unique())\n",
    "    #because no NA values there\n",
    "    alley_dict = {'Grvl':1,'Pave':2,\"NA\":1} \n",
    "    df['Alley'].replace(alley_dict, inplace=True)\n",
    "\n",
    "\n",
    "    # df['LotShape'].fillna('Grvl', inplace=True)\n",
    "    #because no NA values there\n",
    "    # print(df['LotShape'].mode())\n",
    "    df['LotShape'].fillna('Reg', inplace=True)\n",
    "    lot_dict = {'Reg':1,'IR1':2,\"IR2\":3,\"IR3\":4} \n",
    "    df['LotShape'].replace(lot_dict, inplace=True)\n",
    "\n",
    "    df['LandContour'] = df['LandContour'].apply(lambda v: random.choice(['lvl','Bnk','HLS','Low']) if pd.isnull(v) else v)\n",
    "    df['LandContour'].fillna('lvl', inplace=True)\n",
    "    contour_dict = {'lvl':0,'Bnk':1,\"HLS\":1,\"Low\":-1} \n",
    "    df['LandContour'] = df['LandContour'].map(contour_dict)\n",
    "\n",
    "    df = df.drop(['Utilities'], axis=1)\n",
    "\n",
    "    df = get_one_hot(df,'LotConfig',None)\n",
    "\n",
    "    df['LandSlope'].fillna('Gtl', inplace=True)\n",
    "    slope_dict = {'Gtl':1,'Mod':2,\"Sev\":3} \n",
    "    df['LandSlope'] = df['LandSlope'].map(slope_dict)\n",
    "    # print(df.LandSlope.unique())\n",
    "\n",
    "    # Bin by neighborhood (a little arbitrarily). Values were computed by: \n",
    "    # train_df[\"SalePrice\"].groupby(train_df[\"Neighborhood\"]).median().sort_values()\n",
    "    \n",
    "        \n",
    "    df.loc[df.Neighborhood == 'NridgHt', \"Neighborhood_Good\"] = 1   \n",
    "    df.loc[df.Neighborhood == 'Crawfor', \"Neighborhood_Good\"] = 1\n",
    "    df.loc[df.Neighborhood == 'StoneBr', \"Neighborhood_Good\"] = 1\n",
    "    df.loc[df.Neighborhood == 'Somerst', \"Neighborhood_Good\"] = 1\n",
    "    df.loc[df.Neighborhood == 'NoRidge', \"Neighborhood_Good\"] = 1\n",
    "    df[\"Neighborhood_Good\"].fillna(0, inplace=True)\n",
    "\n",
    "    neighborhood_map = {\n",
    "        \"MeadowV\" : 0,  #  88000\n",
    "        \"IDOTRR\" : 1,   # 103000\n",
    "        \"BrDale\" : 1,   # 106000\n",
    "        \"OldTown\" : 1,  # 119000\n",
    "        \"Edwards\" : 1,  # 119500\n",
    "        \"BrkSide\" : 1,  # 124300\n",
    "        \"Sawyer\" : 1,   # 135000\n",
    "        \"Blueste\" : 1,  # 137500\n",
    "        \"SWISU\" : 2,    # 139500\n",
    "        \"NAmes\" : 2,    # 140000\n",
    "        \"NPkVill\" : 2,  # 146000\n",
    "        \"Mitchel\" : 2,  # 153500\n",
    "        \"SawyerW\" : 2,  # 179900\n",
    "        \"Gilbert\" : 2,  # 181000\n",
    "        \"NWAmes\" : 2,   # 182900\n",
    "        \"Blmngtn\" : 2,  # 191000\n",
    "        \"CollgCr\" : 2,  # 197200\n",
    "        \"ClearCr\" : 3,  # 200250\n",
    "        \"Crawfor\" : 3,  # 200624\n",
    "        \"Veenker\" : 3,  # 218000\n",
    "        \"Somerst\" : 3,  # 225500\n",
    "        \"Timber\" : 3,   # 228475\n",
    "        \"StoneBr\" : 4,  # 278000\n",
    "        \"NoRidge\" : 4,  # 290000\n",
    "        \"NridgHt\" : 4,  # 315000\n",
    "    }\n",
    "\n",
    "    df[\"NeighborhoodBin\"] = df[\"Neighborhood\"].map(neighborhood_map)\n",
    "    df = get_one_hot(df,'Neighborhood',None)\n",
    "\n",
    "    for condition in df.Condition1.unique():\n",
    "        if not pd.isnull(condition):\n",
    "            df[condition] = df['Condition1'].map(lambda x: 1 if x == condition else 0)\n",
    "            df[condition] = df[condition] + df['Condition2'].map(lambda x: 1 if x == condition and condition!='Norm' else 0)\n",
    "        \n",
    "    df = df.drop(['Condition1','Condition2'], axis=1)        \n",
    "    # print(df.Norm.unique())\n",
    "    print(df['BldgType'].mode())\n",
    "    \n",
    "    df['hsStl'] = df['HouseStyle']\n",
    "    df['bldtyp'] = df['BldgType']\n",
    "    df = factorize(df,'bldtyp',None)\n",
    "    df = factorize(df,'hsStl',None)\n",
    "\n",
    "    df = get_one_hot(df,'BldgType',None)\n",
    "\n",
    "    df = get_one_hot(df,'HouseStyle',None)\n",
    "\n",
    "\n",
    "\n",
    "# drop_cols = [\n",
    "#                 \"_Exterior1st_ImStucc\", \"_Exterior1st_Stone\",\n",
    "#                 \"_Exterior2nd_Other\",\"_HouseStyle_2.5Fin\", \n",
    "            \n",
    "#                 \"_RoofMatl_Membran\", \"_RoofMatl_Metal\", \"_RoofMatl_Roll\",\n",
    "#                 \"_Condition2_RRAe\", \"_Condition2_RRAn\", \"_Condition2_RRNn\",\n",
    "#                 \"_Heating_Floor\", \"_Heating_OthW\",\n",
    "\n",
    "#                 \"_Electrical_Mix\", \n",
    "#                 \"_MiscFeature_TenC\",\n",
    "#                 \"_GarageQual_Ex\", \"_PoolQC_Fa\"\n",
    "#             ]\n",
    "            \n",
    "# df.drop(drop_cols, axis=1, inplace=True)\n",
    "    year_bin = [i+2000 for i in range(11,0,-1)]\n",
    "    print(year_bin)\n",
    "    year_bin = year_bin+[2000,1990,1980,1970,1960,1950,1940,1920,1900,-1]\n",
    "    df['YearRemodAdd'].fillna(df.YearBuilt, inplace=True)\n",
    "    for i in range(1,len(year_bin)):\n",
    "        df['built_'+str(year_bin[i])] = 0\n",
    "        df.loc[(df.YearBuilt >= year_bin[i]) & (df.YearBuilt < year_bin[i-1]),'built_'+ str(year_bin[i])] = 1\n",
    "        df['remod_'+str(year_bin[i])] = 0\n",
    "        df.loc[(df.YearRemodAdd >= year_bin[i]) & (df.YearRemodAdd < year_bin[i-1]),'remod_'+ str(year_bin[i])] = 1\n",
    "    \n",
    "    year_map = pd.concat(pd.Series(\"YearBin\" + str(i+1), index=range(1871+i*20,1891+i*20)) for i in range(0, 7))\n",
    "\n",
    "    df[\"GarageYrBlt\"].fillna(0.0, inplace=True)\n",
    "\n",
    "    df[\"GarageYrBltBin\"] = df.GarageYrBlt.map(year_map)\n",
    "    df[\"GarageYrBltBin\"].fillna(\"NoGarage\", inplace=True)\n",
    "    df = get_one_hot(df, \"GarageYrBltBin\", None)\n",
    "\n",
    "\n",
    "\n",
    "    df[\"YearsSinceRemodel\"] = df[\"YrSold\"] - df[\"YearRemodAdd\"]\n",
    "\n",
    "    df[\"Remodeled\"] = (df[\"YearRemodAdd\"] != df[\"YearBuilt\"]) * 1\n",
    "    \n",
    "    df[\"RecentRemodel\"] = (df[\"YearRemodAdd\"] == df[\"YrSold\"]) * 1\n",
    "\n",
    "    df[\"VeryNewHouse\"] = (df[\"YearBuilt\"] == df[\"YrSold\"]) * 1\n",
    "\n",
    "    df[\"Age\"] = 2010 - df[\"YearBuilt\"]\n",
    "    df[\"TimeSinceSold\"] = 2010 - df[\"YrSold\"]\n",
    "\n",
    "    df[\"SeasonSold\"] = df[\"MoSold\"].map({12:0, 1:0, 2:0, 3:1, 4:1, 5:1, \n",
    "                                                  6:2, 7:2, 8:2, 9:3, 10:3, 11:3}).astype(int)\n",
    "    \n",
    "    df[\"YearsSinceRemodel\"] = df[\"YrSold\"] - df[\"YearRemodAdd\"]\n",
    "\n",
    "    # df = df.drop(['YearBuilt','YearRemodAdd'], axis=1)        \n",
    "\n",
    "    df = get_one_hot(df,'RoofStyle',df['RoofStyle'].mode()[0])\n",
    "    df = get_one_hot(df,'RoofMatl',df['RoofMatl'].mode()[0])\n",
    "\n",
    "    df['Exterior1st'].fillna(df['Exterior1st'].mode()[0], inplace=True)\n",
    "    df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0], inplace=True)\n",
    "    for condition in df.Exterior1st.unique():\n",
    "        if not pd.isnull(condition):\n",
    "            df[condition] = df['Exterior1st'].map(lambda x: 1 if x == condition else 0)\n",
    "            df[condition] = df[condition] + df['Exterior2nd'].map(lambda x: 1 if x == condition else 0)\n",
    "            df.loc[df[condition]>1,condition] = 1\n",
    "        \n",
    "    df = df.drop(['Exterior1st','Exterior2nd','GarageYrBlt'], axis=1)\n",
    "\n",
    "    df[\"MasVnrArea\"].fillna(0, inplace=True)\n",
    "    idx = (df[\"MasVnrArea\"] != 0) & ((df[\"MasVnrType\"] == \"None\") | (df[\"MasVnrType\"].isnull()))\n",
    "    df.loc[idx, \"MasVnrType\"] = \"BrkFace\"\n",
    "    df = get_one_hot(df,'MasVnrType','None')\n",
    "\n",
    "    df['ExterQual'].fillna('TA', inplace=True)\n",
    "    qual_dict = {'Ex':4,'Gd':3,\"TA\":2,\"Fa\":1,\"Po\":0} \n",
    "    df['ExterQual'].replace(qual_dict, inplace=True)\n",
    "    \n",
    "    df = get_one_hot(df,'Foundation',df['Foundation'].mode()[0])\n",
    "\n",
    "    df['BsmtQual'].fillna('TA', inplace=True)\n",
    "    qual_dict = {'Ex':4,'Gd':3,\"TA\":2,\"Fa\":1,\"Po\":0,\"NA\":-2} \n",
    "    df['BsmtQual'].replace(qual_dict, inplace=True)\n",
    "    df['BsmtCond'].replace(qual_dict, inplace=True)\n",
    "\n",
    "    # df['BsmtExposure'].fillna('TA', inplace=True)\n",
    "    qual_dict = {'Gd':3,'Av':2,\"Mn\":1,\"No\":0,None:-2} \n",
    "    df['BsmtExposure'].replace(qual_dict, inplace=True)\n",
    "    # df['BsmtExposure'].replace(qual_dict, inplace=True)\n",
    "\n",
    "# bsmt_fin_dict = {None: 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6}\n",
    "# df[\"BsmtFinType1\"] = df[\"BsmtFinType1\"].map(bsmt_fin_dict).astype(int)\n",
    "# df[\"BsmtFinType2\"] = df[\"BsmtFinType2\"].map(bsmt_fin_dict).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    df['BsmtFinType1'].fillna(df['BsmtFinType1'].mode()[0], inplace=True)\n",
    "    df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0], inplace=True)\n",
    "    for condition in df.BsmtFinType1.unique():\n",
    "        if not pd.isnull(condition):\n",
    "            df[condition] = df['BsmtFinType1'].map(lambda x: 1 if x == condition else 0)\n",
    "            df[condition] = df[condition] + df['BsmtFinType2'].map(lambda x: 1 if x == condition else 0)\n",
    "            df.loc[df[condition]>1,condition] = 1\n",
    "        \n",
    "    df = df.drop(['BsmtFinType1','BsmtFinType2'], axis=1)\n",
    "\n",
    "    qual_dict = {'None':-1,\"NA\":-1,None: 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n",
    "    df[\"ExterCond\"] = df[\"ExterCond\"].map(qual_dict).astype(int)\n",
    "    df[\"HeatingQC\"] = df[\"HeatingQC\"].map(qual_dict).astype(int)\n",
    "    \n",
    "        # description says NA = no pool, but there are entries with PoolArea >0 and PoolQC = NA. Fill the ones with values with average condition\n",
    "    df.loc[(df['PoolQC'].isnull()) & (df['PoolArea']==0), 'PoolQC' ] = 'None'\n",
    "    df.loc[(df['PoolQC'].isnull()) & (df['PoolArea']>0), 'PoolQC' ] = 'TA'\n",
    "    df[\"PoolQC\"] = df[\"PoolQC\"].map(qual_dict).astype(int)\n",
    "    df[\"KitchenQual\"] = df[\"KitchenQual\"].map(qual_dict).astype(int)\n",
    "    df[\"FireplaceQu\"] = df[\"FireplaceQu\"].map(qual_dict).astype(int)\n",
    "    df[\"GarageQual\"] = df[\"GarageQual\"].map(qual_dict).astype(int)\n",
    "    df[\"GarageCond\"] = df[\"GarageCond\"].map(qual_dict).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    df[\"Functional\"] = df[\"Functional\"].map(\n",
    "        {None: 0, \"Sal\": 1, \"Sev\": 2, \"Maj2\": 3, \"Maj1\": 4, \n",
    "         \"Mod\": 5, \"Min2\": 6, \"Min1\": 7, \"Typ\": 8}).astype(int)\n",
    "         \n",
    "    df[\"SimplOverallQual\"] = df.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                                       4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                                      })\n",
    "    df[\"SimplOverallCond\"] = df.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                                       4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                                      })\n",
    "    df[\"SimplPoolQC\"] = df.PoolQC.replace({1 : 1, 2 : 1, # average\n",
    "                                             3 : 2, 4 : 2 # good\n",
    "                                            })\n",
    "    df[\"SimplGarageCond\"] = df.GarageCond.replace({1 : 1, # bad\n",
    "                                                     2 : 1, 3 : 1, # average\n",
    "                                                     4 : 2, 5 : 2 # good\n",
    "                                                    })\n",
    "    df[\"SimplGarageQual\"] = df.GarageQual.replace({1 : 1, # bad\n",
    "                                                     2 : 1, 3 : 1, # average\n",
    "                                                     4 : 2, 5 : 2 # good\n",
    "                                                    })\n",
    "    df[\"SimplFireplaceQu\"] = df.FireplaceQu.replace({1 : 1, # bad\n",
    "                                                       2 : 1, 3 : 1, # average\n",
    "                                                       4 : 2, 5 : 2 # good\n",
    "                                                      })\n",
    "    df[\"SimplFireplaceQu\"] = df.FireplaceQu.replace({1 : 1, # bad\n",
    "                                                       2 : 1, 3 : 1, # average\n",
    "                                                       4 : 2, 5 : 2 # good\n",
    "                                                      })\n",
    "    df[\"SimplFunctional\"] = df.Functional.replace({1 : 1, 2 : 1, # bad\n",
    "                                                     3 : 2, 4 : 2, # major\n",
    "                                                     5 : 3, 6 : 3, 7 : 3, # minor\n",
    "                                                     8 : 4 # typical\n",
    "                                                    })\n",
    "    df[\"SimplKitchenQual\"] = df.KitchenQual.replace({1 : 1, # bad\n",
    "                                                       2 : 1, 3 : 1, # average\n",
    "                                                       4 : 2, 5 : 2 # good\n",
    "                                                      })\n",
    "    df[\"SimplHeatingQC\"] = df.HeatingQC.replace({1 : 1, # bad\n",
    "                                                   2 : 1, 3 : 1, # average\n",
    "                                                   4 : 2, 5 : 2 # good\n",
    "                                                  })\n",
    "                                                  \n",
    "\n",
    "\n",
    "    electric_dict = {'SBrkr':5,'FuseA':0,'Mix':2,'FuseF':-1,'FuseP':-2}\n",
    "    df['Electrical'].replace(electric_dict, inplace=True)\n",
    "\n",
    "    air_dict = {'N':0,'Y':1}\n",
    "    df['CentralAir'].replace(air_dict, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    garage_dict = {'Fin':2,'RFn':1,'Unf':-1,'NA':-5}\n",
    "    df['GarageFinish'].replace(garage_dict, inplace=True)\n",
    "\n",
    "    pave_dict = {'Y':1,'P':0,'N':-1}\n",
    "    df['PavedDrive'].replace(pave_dict, inplace=True)\n",
    "\n",
    "    df[\"Fence\"] = df[\"Fence\"].map(\n",
    "            {None: 0, \"MnWw\": 1, \"GdWo\": 2, \"MnPrv\": 3, \"GdPrv\": 4}).astype(int)\n",
    "    df = get_one_hot(df,'Fence',0)\n",
    "\n",
    "\n",
    "    #dealing with area related fields.\n",
    "    df[\"BsmtFinSF1\"].fillna(0, inplace=True)\n",
    "    df[\"BsmtFinSF2\"].fillna(0, inplace=True)\n",
    "    df[\"BsmtUnfSF\"].fillna(0, inplace=True)\n",
    "    df[\"TotalBsmtSF\"].fillna(0, inplace=True)\n",
    "    df[\"GarageArea\"].fillna(0, inplace=True)\n",
    "    df[\"BsmtFullBath\"].fillna(0, inplace=True)\n",
    "    df[\"BsmtHalfBath\"].fillna(0, inplace=True)\n",
    "    df[\"GarageCars\"].fillna(0, inplace=True)\n",
    "    df[\"PoolArea\"].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    df[\"IsRegularLotShape\"] = (df[\"LotShape\"] == 1) * 1\n",
    "\n",
    "    # Most properties are level; bin the other possibilities together\n",
    "    # as \"not level\".\n",
    "    df[\"IsLandLevel\"] = (df[\"LandContour\"] == 0) * 1\n",
    "\n",
    "    # Most land slopes are gentle; treat the others as \"not gentle\".\n",
    "    df[\"IsLandSlopeGentle\"] = (df[\"LandSlope\"] == 1) * 1\n",
    "\n",
    "    # Most properties use standard circuit breakers.\n",
    "    df[\"IsElectricalSBrkr\"] = (df[\"Electrical\"] == 5) * 1\n",
    "\n",
    "    # About 2/3rd have an attached garage.\n",
    "    df[\"IsGarageDetached\"] = (df[\"GarageType\"] == \"Detchd\") * 1\n",
    "\n",
    "    # Most have a paved drive. Treat dirt/gravel and partial pavement\n",
    "    # as \"not paved\".\n",
    "    df[\"IsPavedDrive\"] = (df[\"PavedDrive\"] == 1) * 1\n",
    "\n",
    "    # The only interesting \"misc. feature\" is the presence of a shed.\n",
    "    df[\"HasShed\"] = (df[\"MiscFeature\"] == \"Shed\") * 1.  \n",
    "\n",
    "\n",
    "\n",
    "    df[\"Has2ndFloor\"] = (df[\"2ndFlrSF\"] == 0) * 1\n",
    "    df[\"HasMasVnr\"] = (df[\"MasVnrArea\"] == 0) * 1\n",
    "    df[\"HasWoodDeck\"] = (df[\"WoodDeckSF\"] == 0) * 1\n",
    "    df[\"HasOpenPorch\"] = (df[\"OpenPorchSF\"] == 0) * 1\n",
    "    df[\"HasEnclosedPorch\"] = (df[\"EnclosedPorch\"] == 0) * 1\n",
    "    df[\"Has3SsnPorch\"] = (df[\"3SsnPorch\"] == 0) * 1\n",
    "    df[\"HasScreenPorch\"] = (df[\"ScreenPorch\"] == 0) * 1\n",
    "\n",
    "\n",
    "    # Months with the largest number of deals may be significant.\n",
    "    df[\"HighSeason\"] = df[\"MoSold\"].replace( \n",
    "        {1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0})\n",
    "\n",
    "    df[\"NewerDwelling\"] = df[\"MSSubClass\"].replace(\n",
    "        {20: 1, 30: 0, 40: 0, 45: 0,50: 0, 60: 1, 70: 0, 75: 0, 80: 0, 85: 0,\n",
    "         90: 0, 120: 1, 150: 0, 160: 0, 180: 0, 190: 0})   \n",
    "\n",
    "\n",
    "    df[\"SaleCondition_PriceDown\"] = df.SaleCondition.replace(\n",
    "        {'Abnorml': 1, 'Alloca': 1, 'AdjLand': 1, 'Family': 1, 'Normal': 0, 'Partial': 0})\n",
    "\n",
    "    # House completed before sale or not\n",
    "    df[\"BoughtOffPlan\"] = df.SaleCondition.replace(\n",
    "        {\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n",
    "    \n",
    "\n",
    "    area_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', \n",
    "                 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'LowQualFinSF', 'PoolArea' ]\n",
    "\n",
    "    df[\"TotalArea\"] = df[area_cols].sum(axis=1)\n",
    "\n",
    "    df[\"TotalArea1st2nd\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n",
    "    df['All_Liv_SF'] = np.log1p(df['TotalArea1st2nd'] + df['LowQualFinSF'] + df['GrLivArea'])\n",
    "    \n",
    "    for col in area_cols+['TotalArea','TotalArea1st2nd']:\n",
    "        df[col].map(lambda x:np.log1p(x))\n",
    "        \n",
    "    area_cols = area_cols+['TotalArea','TotalArea1st2nd','All_Liv_SF']\n",
    "    \n",
    "    sub_df = df[area_cols]\n",
    "    array_standard = StandardScaler().fit_transform(sub_df)\n",
    "    df_standard = pd.DataFrame(array_standard, df.index, area_cols)\n",
    "    df.drop(df[area_cols], axis=1, inplace=True)\n",
    "    df = pd.concat([df, df_standard], axis=1)\n",
    "    \n",
    "    \n",
    "    df = get_one_hot(df,'Functional','Typ')\n",
    "    df = get_one_hot(df,'GarageType','NA')\n",
    "\n",
    "    df = get_one_hot(df, \"SaleType\", \"WD\")\n",
    "    df = get_one_hot(df, \"SaleCondition\", \"Normal\")                                                  \n",
    "    df = get_one_hot(df,'Heating','none')\n",
    "    df = get_one_hot(df,'MiscFeature','none')\n",
    "    df['month'] = df['MoSold']\n",
    "    df = get_one_hot(df,'MoSold','none')\n",
    "\n",
    "    drop_cols = [\n",
    "                \"_Exterior1st_ImStucc\", \"_Exterior1st_Stone\",\n",
    "                \"_Exterior2nd_Other\",\"_HouseStyle_2.5Fin\", \n",
    "            \n",
    "                \"_RoofMatl_Membran\", \"_RoofMatl_Metal\", \"_RoofMatl_Roll\",\n",
    "                \"_Condition2_RRAe\", \"_Condition2_RRAn\", \"_Condition2_RRNn\",\n",
    "                \"_Heating_Floor\", \"_Heating_OthW\",\n",
    "\n",
    "                \"_Electrical_Mix\", \n",
    "                \"_MiscFeature_TenC\",\n",
    "                \"_GarageQual_Ex\", \"_PoolQC_Fa\",\"_MSSubCls_150\", \"_MSSubCls_150.0\",\"_Condition2_PosN\",    # only two are not zero\n",
    "    \"_MSZoning_C (all)\",\n",
    "    \"_MSSubCls_160\", 'Stone', 'ImStucc','_HouseStyle_7','_RoofMatl_ClyTile','_Functional_0'\n",
    "            ]\n",
    "    for col in drop_cols:\n",
    "        try:\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return df\n",
    "#end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[666, \"GarageQual\"] = \"TA\"\n",
    "test.loc[666, \"GarageCond\"] = \"TA\"\n",
    "test.loc[666, \"GarageFinish\"] = \"Unf\"\n",
    "test.loc[666, \"GarageYrBlt\"] = \"1980\"\n",
    "\n",
    "# The test example 1116 only has GarageType but no other information. We'll \n",
    "# assume it does not have a garage.\n",
    "test.loc[1116, \"GarageType\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do the feature engineering on the training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning      C (all)  FV  RH   RL  RM\n",
      "Neighborhood                          \n",
      "Blmngtn             0   0   0   16   1\n",
      "Blueste             0   0   0    0   2\n",
      "BrDale              0   0   0    0  16\n",
      "BrkSide             0   0   0   28  30\n",
      "ClearCr             0   0   0   28   0\n",
      "CollgCr             0   0   0  140  10\n",
      "Crawfor             0   0   2   46   3\n",
      "Edwards             0   0   2   90   8\n",
      "Gilbert             0   0   0   79   0\n",
      "IDOTRR              9   0   0    0  28\n",
      "MeadowV             0   0   0    0  17\n",
      "Mitchel             0   0   0   44   5\n",
      "NAmes               0   0   2  223   0\n",
      "NPkVill             0   0   0    9   0\n",
      "NWAmes              0   0   0   73   0\n",
      "NoRidge             0   0   0   41   0\n",
      "NridgHt             0   0   0   76   1\n",
      "OldTown             1   0   0   17  95\n",
      "SWISU               0   0   5   20   0\n",
      "Sawyer              0   0   0   72   2\n",
      "SawyerW             0   0   5   54   0\n",
      "Somerst             0  65   0   21   0\n",
      "StoneBr             0   0   0   25   0\n",
      "Timber              0   0   0   38   0\n",
      "Veenker             0   0   0   11   0\n",
      "['NA' 'Grvl' 'Pave']\n",
      "0    1Fam\n",
      "dtype: object\n",
      "[2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2003, 2002, 2001]\n",
      "MSZoning      C (all)  FV  RH   RL   RM\n",
      "Neighborhood                           \n",
      "Blmngtn             0   0   0    9    2\n",
      "Blueste             0   0   0    0    8\n",
      "BrDale              0   0   0    0   14\n",
      "BrkSide             0   0   0   15   35\n",
      "ClearCr             0   0   0   16    0\n",
      "CollgCr             0   0   0  113    4\n",
      "Crawfor             0   0   0   45    7\n",
      "Edwards             0   0   0   90    4\n",
      "Gilbert             0   0   0   86    0\n",
      "IDOTRR             13   0   0    0   40\n",
      "MeadowV             0   0   0    0   20\n",
      "Mitchel             0   0   0   60    4\n",
      "NAmes               0   0   5  213    0\n",
      "NPkVill             0   0   0   14    0\n",
      "NWAmes              0   0   0   58    0\n",
      "NoRidge             0   0   0   30    0\n",
      "NridgHt             0   0   0   89    0\n",
      "OldTown             1   0   0   22  103\n",
      "SWISU               1   0   4   18    0\n",
      "Sawyer              0   0   0   76    1\n",
      "SawyerW             0   0   1   65    0\n",
      "Somerst             0  74   0   22    0\n",
      "StoneBr             0   0   0   26    0\n",
      "Timber              0   0   0   34    0\n",
      "Veenker             0   0   0   13    0\n",
      "['NA' 'Pave' 'Grvl']\n",
      "0    1Fam\n",
      "dtype: object\n",
      "[2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2003, 2002, 2001]\n"
     ]
    }
   ],
   "source": [
    "target_vector = pd.DataFrame(index = train.index, columns=[\"SalePrice\"])\n",
    "target_vector[\"SalePrice\"] = train[\"SalePrice\"]\n",
    "\n",
    "#remove SalePrice from training data\n",
    "train.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "#now let us do the feature engineering on train and testing data sets\n",
    "train = feature_engineering(train)\n",
    "test = feature_engineering(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatter plots of GrLiveArea and GarageArea, we can see that a few outliers are there. Since they are not many, we can delete them from the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_row_count = train.shape[0]\n",
    "\n",
    "# fix all extreme outliers based on outlier analysis\n",
    "# 8 rows will be deleted\n",
    "train = train[train.GrLivArea <= 4000]\n",
    "train = train[train.GarageArea <= 1200]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute all the null values with mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set size:', (1460, 306))\n",
      "('Test set size:', (1459, 306))\n"
     ]
    }
   ],
   "source": [
    "train = train.fillna(train.mean())\n",
    "test = test.fillna(train.mean())\n",
    "\n",
    "train.sort_index(axis=1, inplace=True)\n",
    "test.sort_index(axis=1,inplace=True)\n",
    "\n",
    "#print (set(list(test)-set(list(train))))\n",
    "       \n",
    "print(\"Training set size:\", train.shape)\n",
    "print(\"Test set size:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After feature engineering is done, we have 308 features in the training and test data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the training and testing data after categorical factorization. We will continue the next notebook module - pre-processing. Let us save the trainig and testing data into file system so that next steps can continue from the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and test data are saved\n"
     ]
    }
   ],
   "source": [
    "#add the sale price back onto training data\n",
    "train[\"SalePrice\"] = target_vector[\"SalePrice\"]\n",
    "\n",
    "train.to_csv('../data/train_after_feature_engineering.csv', header=True, index=False)\n",
    "test.to_csv('../data/test_after_feature_engineering.csv', header=True, index=False)\n",
    "\n",
    "print('training and test data are saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
